{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option(\"display.width\", 500)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing your CSV files\n",
    "csv_directory = \"../data/\"\n",
    "\n",
    "# Define the output directory for user action files\n",
    "output_directory = \"../data_users/\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Load user IDs from Parquet files\n",
    "super_users_df = pd.read_parquet(\"../data_users/SuperUserIds.parquet\")\n",
    "# non_super_users_df = pd.read_parquet(\"../data_users/NonSuperUserIds.parquet\")\n",
    "\n",
    "# Convert DataFrames to sets for faster lookup\n",
    "super_user_ids = set(super_users_df[\"Id\"].astype(int))\n",
    "# non_super_user_ids = set(non_super_users_df[\"Id\"].astype(int))\n",
    "\n",
    "# Mapping of CSV files to user ID columns and action types\n",
    "file_mappings = {\n",
    "    \"Votes.csv\": {\n",
    "        \"user_id_column\": \"UserId\",\n",
    "        \"action_type_column\": \"VoteTypeId\",\n",
    "        \"action_type_map\": {2: \"UpVote\", 3: \"DownVote\"},\n",
    "        \"date_column\": \"CreationDate\",\n",
    "    },\n",
    "    \"Posts.csv\": {\n",
    "        \"user_id_column\": \"OwnerUserId\",\n",
    "        \"action_type_column\": \"PostTypeId\",\n",
    "        \"action_type_map\": {1: \"Question\", 2: \"Answer\"},\n",
    "        \"date_column\": \"CreationDate\",\n",
    "    },\n",
    "    \"Comments.csv\": {\n",
    "        \"user_id_column\": \"UserId\",\n",
    "        \"action_type\": \"Comment\",\n",
    "        \"date_column\": \"CreationDate\",\n",
    "    },\n",
    "    \"Badges.csv\": {\n",
    "        \"user_id_column\": \"UserId\",\n",
    "        \"action_type\": \"Badge\",\n",
    "        \"date_column\": \"Date\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define the columns to extract for each file\n",
    "columns_mapping = {\n",
    "    \"Posts.csv\": [\"OwnerUserId\", \"CreationDate\", \"PostTypeId\"],\n",
    "    \"Comments.csv\": [\"UserId\", \"CreationDate\"],\n",
    "    \"Votes.csv\": [\"UserId\", \"CreationDate\", \"VoteTypeId\"],\n",
    "    \"Badges.csv\": [\"UserId\", \"Date\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_output_files(output_dir):\n",
    "    \"\"\"\n",
    "    Initialize consolidated output files with headers.\n",
    "    \"\"\"\n",
    "    super_output_path = os.path.join(output_dir, \"super_users_actions.csv\")\n",
    "    non_super_output_path = os.path.join(output_dir, \"non_super_users_actions.csv\")\n",
    "    \n",
    "    if not os.path.exists(super_output_path):\n",
    "        with open(super_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"UserId,ActionType,CreationDate\\n\")\n",
    "    \n",
    "    if not os.path.exists(non_super_output_path):\n",
    "        with open(non_super_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"UserId,ActionType,CreationDate\\n\")\n",
    "\n",
    "def process_file(file_name, mapping, columns, user_ids, output_file, chunksize=10**6):\n",
    "    \"\"\"\n",
    "    Process a single CSV file in chunks, filter actions for target users,\n",
    "    and append them to the consolidated output file.\n",
    "    \"\"\"\n",
    "    print(mapping)\n",
    "    file_path = os.path.join(csv_directory, file_name)\n",
    "\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    date_column = mapping.get('date_column', 'CreationDate')\n",
    "\n",
    "    # Read the CSV in chunks\n",
    "    try:\n",
    "        csv_iterator = pd.read_csv(\n",
    "            file_path,\n",
    "            chunksize=chunksize,\n",
    "            usecols=columns,\n",
    "            parse_dates=[date_column],\n",
    "            iterator=True,\n",
    "            delimiter='\\x17',\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_name} not found in {csv_directory}. Skipping.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_name}: {e}\")\n",
    "        return\n",
    "\n",
    "    action_type_column = mapping.get('action_type_column')\n",
    "    action_type_map = mapping.get('action_type_map', {})\n",
    "    default_action_type = mapping.get('action_type', 'Action')\n",
    "\n",
    "    # calculate number of chunks for tqdm\n",
    "    # num_chunks = sum(1 for _ in pd.read_csv(file_path, chunksize=chunksize, delimiter='\\x17'))\n",
    "\n",
    "    print(f\"Filtering actions for {len(user_ids)} target users...\")\n",
    "    # Iterate over each chunk\n",
    "    for chunk in tqdm(csv_iterator, desc=f\"Processing {file_name}\", unit=\"chunk\"):\n",
    "        # Drop rows with missing user IDs or date\n",
    "        chunk.dropna(subset=[mapping['user_id_column'], date_column], inplace=True)\n",
    "\n",
    "        # Ensure user ID is of integer type if necessary\n",
    "        chunk[mapping['user_id_column']] = chunk[mapping['user_id_column']].astype(int)\n",
    "\n",
    "        # print(chunk)\n",
    "\n",
    "        # Filter rows where the user ID is in target_user_ids\n",
    "        filtered_chunk = chunk[chunk[mapping['user_id_column']].isin(user_ids)]\n",
    "\n",
    "        if filtered_chunk.empty:\n",
    "            continue  # Skip if no relevant actions in this chunk\n",
    "\n",
    "        # Prepare action records\n",
    "        records = []\n",
    "        for _, row in filtered_chunk.iterrows():\n",
    "            # print(row)\n",
    "            user_id = row[mapping['user_id_column']]\n",
    "            creation_date = row[date_column].isoformat()\n",
    "\n",
    "            if action_type_column and row[action_type_column] in action_type_map:\n",
    "                action_type = action_type_map[row[action_type_column]]\n",
    "            else:\n",
    "                action_type = default_action_type\n",
    "\n",
    "            records.append(f\"{user_id},{action_type},{creation_date}\\n\")\n",
    "\n",
    "        # Append records to the consolidated output file\n",
    "        with open(output_file, 'a', encoding='utf-8') as f:\n",
    "            f.writelines(records)\n",
    "\n",
    "    print(f\"Finished processing {file_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id_column': 'UserId', 'action_type_column': 'VoteTypeId', 'action_type_map': {2: 'UpVote', 3: 'DownVote'}, 'date_column': 'CreationDate'}\n",
      "Processing Votes.csv...\n",
      "Filtering actions for 22076 target users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535a6e395b534a14916544689069f728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Votes.csv: 0chunk [00:00, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing Votes.csv.\n",
      "{'user_id_column': 'OwnerUserId', 'action_type_column': 'PostTypeId', 'action_type_map': {1: 'Question', 2: 'Answer'}, 'date_column': 'CreationDate'}\n",
      "Processing Posts.csv...\n",
      "Filtering actions for 22076 target users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8654e0643ee4cf7bd80652f297f6b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Posts.csv: 0chunk [00:00, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing Posts.csv.\n",
      "{'user_id_column': 'UserId', 'action_type': 'Comment', 'date_column': 'CreationDate'}\n",
      "Processing Comments.csv...\n",
      "Filtering actions for 22076 target users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a812bf2d62954474a53627bb95744346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Comments.csv: 0chunk [00:00, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing Comments.csv.\n",
      "{'user_id_column': 'UserId', 'action_type': 'Badge', 'date_column': 'Date'}\n",
      "Processing Badges.csv...\n",
      "Filtering actions for 22076 target users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff53e2a4632495097739f8457bc51df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Badges.csv: 0chunk [00:00, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing Badges.csv.\n"
     ]
    }
   ],
   "source": [
    "# Initialize consolidated output files\n",
    "initialize_output_files(output_directory)\n",
    "\n",
    "# Define output file paths\n",
    "super_output_path = os.path.join(output_directory, \"super_users_actions.csv\")\n",
    "\n",
    "# remove the output paths if they already exist\n",
    "if os.path.exists(super_output_path):\n",
    "    os.remove(super_output_path)\n",
    "\n",
    "# Process files for Super Users\n",
    "for file_name, mapping in file_mappings.items():\n",
    "    columns = columns_mapping.get(file_name, [mapping['user_id_column'], 'CreationDate'])\n",
    "    process_file(\n",
    "        file_name=file_name,\n",
    "        mapping=mapping,\n",
    "        columns=columns,\n",
    "        user_ids=super_user_ids,\n",
    "        output_file=super_output_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id_column': 'UserId', 'action_type_column': 'VoteTypeId', 'action_type_map': {2: 'UpVote', 3: 'DownVote'}, 'date_column': 'CreationDate'}\n",
      "Processing Votes.csv...\n",
      "Filtering actions for 220533 target users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d2cfab63c6434aaac61e8e644f4557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Votes.csv: 0chunk [00:00, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_super_sample = pd.read_parquet(\"../data_users/NonSuperUserIdsSample.parquet\")\n",
    "non_super_user_ids = set(non_super_sample[\"Id\"].astype(int))\n",
    "\n",
    "non_super_output_path = os.path.join(output_directory, \"non_super_users_actions.csv\")\n",
    "\n",
    "if os.path.exists(non_super_output_path):\n",
    "    os.remove(non_super_output_path)\n",
    "    \n",
    "# Process files for Non-Super Users\n",
    "for file_name, mapping in file_mappings.items():\n",
    "    columns = columns_mapping.get(file_name, [mapping['user_id_column'], 'CreationDate'])\n",
    "    process_file(\n",
    "        file_name=file_name,\n",
    "        mapping=mapping,\n",
    "        columns=columns,\n",
    "        user_ids=non_super_user_ids,\n",
    "        output_file=non_super_output_path\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
